{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本中总共有6756个中文字符,全部字符进入字典\n",
      "一共有490259个句子\n",
      "0 sentences dealed, loss: 319.42376709\n",
      "1000 sentences dealed, loss: 166.099380493\n",
      "2000 sentences dealed, loss: 84.8965911865\n",
      "3000 sentences dealed, loss: 32.1872406006\n",
      "4000 sentences dealed, loss: 25.3989276886\n",
      "5000 sentences dealed, loss: 19.6243610382\n",
      "6000 sentences dealed, loss: 14.8132171631\n",
      "7000 sentences dealed, loss: 11.492647171\n",
      "8000 sentences dealed, loss: 9.64089870453\n",
      "9000 sentences dealed, loss: 8.96515655518\n",
      "10000 sentences dealed, loss: 8.74445152283\n",
      "11000 sentences dealed, loss: 6.27566814423\n",
      "12000 sentences dealed, loss: 7.05991363525\n",
      "13000 sentences dealed, loss: 7.9525809288\n",
      "14000 sentences dealed, loss: 5.72894859314\n",
      "15000 sentences dealed, loss: 7.75637340546\n",
      "16000 sentences dealed, loss: 4.61510181427\n",
      "17000 sentences dealed, loss: 4.04460573196\n",
      "18000 sentences dealed, loss: 5.63016414642\n",
      "19000 sentences dealed, loss: 4.59554672241\n",
      "20000 sentences dealed, loss: 4.15906858444\n",
      "21000 sentences dealed, loss: 4.20365142822\n",
      "22000 sentences dealed, loss: 4.43038797379\n",
      "23000 sentences dealed, loss: 4.51763629913\n",
      "24000 sentences dealed, loss: 4.71385335922\n",
      "25000 sentences dealed, loss: 7.43376016617\n",
      "26000 sentences dealed, loss: 3.65062522888\n",
      "27000 sentences dealed, loss: 4.42336940765\n",
      "28000 sentences dealed, loss: 3.81099057198\n",
      "29000 sentences dealed, loss: 3.98796010017\n",
      "30000 sentences dealed, loss: 4.40811109543\n",
      "31000 sentences dealed, loss: 4.38647460938\n",
      "32000 sentences dealed, loss: 3.73485565186\n",
      "33000 sentences dealed, loss: 4.73221874237\n",
      "34000 sentences dealed, loss: 3.67542386055\n",
      "35000 sentences dealed, loss: 3.91221308708\n",
      "36000 sentences dealed, loss: 3.94836759567\n",
      "37000 sentences dealed, loss: 3.96785473824\n",
      "38000 sentences dealed, loss: 4.66261100769\n",
      "39000 sentences dealed, loss: 3.4635155201\n",
      "40000 sentences dealed, loss: 5.02872610092\n",
      "41000 sentences dealed, loss: 3.78500056267\n",
      "42000 sentences dealed, loss: 4.4213757515\n",
      "43000 sentences dealed, loss: 3.46316599846\n",
      "44000 sentences dealed, loss: 3.05803918839\n",
      "45000 sentences dealed, loss: 3.73165631294\n",
      "46000 sentences dealed, loss: 3.10688447952\n",
      "47000 sentences dealed, loss: 3.241345644\n",
      "48000 sentences dealed, loss: 3.47421121597\n",
      "49000 sentences dealed, loss: 3.49947786331\n",
      "50000 sentences dealed, loss: 3.3379406929\n",
      "51000 sentences dealed, loss: 3.16949677467\n",
      "52000 sentences dealed, loss: 3.17209863663\n",
      "53000 sentences dealed, loss: 3.21274328232\n",
      "54000 sentences dealed, loss: 4.93097925186\n",
      "55000 sentences dealed, loss: 3.0320584774\n",
      "56000 sentences dealed, loss: 3.41777420044\n",
      "57000 sentences dealed, loss: 2.89732718468\n",
      "58000 sentences dealed, loss: 4.24299383163\n",
      "59000 sentences dealed, loss: 3.0299141407\n",
      "60000 sentences dealed, loss: 4.901034832\n",
      "61000 sentences dealed, loss: 3.57922887802\n",
      "62000 sentences dealed, loss: 3.28486633301\n",
      "63000 sentences dealed, loss: 3.20284342766\n",
      "64000 sentences dealed, loss: 2.86523580551\n",
      "65000 sentences dealed, loss: 3.17131495476\n",
      "66000 sentences dealed, loss: 2.98472452164\n",
      "67000 sentences dealed, loss: 3.1434044838\n",
      "68000 sentences dealed, loss: 2.71055936813\n",
      "69000 sentences dealed, loss: 3.09656405449\n",
      "70000 sentences dealed, loss: 3.06153726578\n",
      "71000 sentences dealed, loss: 3.02318143845\n",
      "72000 sentences dealed, loss: 2.88977622986\n",
      "73000 sentences dealed, loss: 3.16568350792\n",
      "74000 sentences dealed, loss: 3.08262968063\n",
      "75000 sentences dealed, loss: 3.19295668602\n",
      "76000 sentences dealed, loss: 2.64686608315\n",
      "77000 sentences dealed, loss: 3.38756227493\n",
      "78000 sentences dealed, loss: 3.53868675232\n",
      "79000 sentences dealed, loss: 3.03334188461\n",
      "80000 sentences dealed, loss: 3.14801263809\n",
      "81000 sentences dealed, loss: 3.01491880417\n",
      "82000 sentences dealed, loss: 2.87835836411\n",
      "83000 sentences dealed, loss: 3.25843930244\n",
      "84000 sentences dealed, loss: 4.37288665771\n",
      "85000 sentences dealed, loss: 3.25017356873\n",
      "86000 sentences dealed, loss: 2.9621694088\n",
      "87000 sentences dealed, loss: 2.62600326538\n",
      "88000 sentences dealed, loss: 2.87784123421\n",
      "89000 sentences dealed, loss: 3.01161813736\n",
      "90000 sentences dealed, loss: 3.37948226929\n",
      "91000 sentences dealed, loss: 3.69340968132\n",
      "92000 sentences dealed, loss: 3.59484982491\n",
      "93000 sentences dealed, loss: 2.85839128494\n",
      "94000 sentences dealed, loss: 3.03191161156\n",
      "95000 sentences dealed, loss: 2.75849676132\n",
      "96000 sentences dealed, loss: 2.64347052574\n",
      "97000 sentences dealed, loss: 4.79311466217\n",
      "98000 sentences dealed, loss: 3.34550046921\n",
      "99000 sentences dealed, loss: 3.33925771713\n",
      "100000 sentences dealed, loss: 4.27660274506\n",
      "101000 sentences dealed, loss: 2.97003555298\n",
      "102000 sentences dealed, loss: 3.99105215073\n",
      "103000 sentences dealed, loss: 3.33171582222\n",
      "104000 sentences dealed, loss: 4.01166057587\n",
      "105000 sentences dealed, loss: 3.18777990341\n",
      "106000 sentences dealed, loss: 2.86722111702\n",
      "107000 sentences dealed, loss: 2.69229865074\n",
      "108000 sentences dealed, loss: 2.67304754257\n",
      "109000 sentences dealed, loss: 3.71952629089\n",
      "110000 sentences dealed, loss: 2.90784525871\n",
      "111000 sentences dealed, loss: 3.07596540451\n",
      "112000 sentences dealed, loss: 3.28628230095\n",
      "113000 sentences dealed, loss: 3.05656862259\n",
      "114000 sentences dealed, loss: 3.84601783752\n",
      "115000 sentences dealed, loss: 2.77681350708\n",
      "116000 sentences dealed, loss: 2.98437523842\n",
      "117000 sentences dealed, loss: 3.07348299026\n",
      "118000 sentences dealed, loss: 3.31893229485\n",
      "119000 sentences dealed, loss: 3.62901163101\n",
      "120000 sentences dealed, loss: 2.94450855255\n",
      "121000 sentences dealed, loss: 3.28388524055\n",
      "122000 sentences dealed, loss: 2.8113656044\n",
      "123000 sentences dealed, loss: 4.37005376816\n",
      "124000 sentences dealed, loss: 3.71143865585\n",
      "125000 sentences dealed, loss: 4.09213447571\n",
      "126000 sentences dealed, loss: 4.57477664948\n",
      "127000 sentences dealed, loss: 3.61485099792\n",
      "128000 sentences dealed, loss: 3.88620901108\n",
      "129000 sentences dealed, loss: 3.50635480881\n",
      "130000 sentences dealed, loss: 5.62207317352\n",
      "131000 sentences dealed, loss: 3.53597593307\n",
      "132000 sentences dealed, loss: 4.07501745224\n",
      "133000 sentences dealed, loss: 4.8423166275\n",
      "134000 sentences dealed, loss: 3.86521720886\n",
      "135000 sentences dealed, loss: 3.53135681152\n",
      "136000 sentences dealed, loss: 3.82822680473\n",
      "137000 sentences dealed, loss: 2.96811842918\n",
      "138000 sentences dealed, loss: 3.49918174744\n",
      "139000 sentences dealed, loss: 3.1488032341\n",
      "140000 sentences dealed, loss: 3.67182803154\n",
      "141000 sentences dealed, loss: 2.91934895515\n",
      "142000 sentences dealed, loss: 3.10130190849\n",
      "143000 sentences dealed, loss: 3.0476500988\n",
      "144000 sentences dealed, loss: 4.30397415161\n",
      "145000 sentences dealed, loss: 3.89356160164\n",
      "146000 sentences dealed, loss: 3.28173112869\n",
      "147000 sentences dealed, loss: 3.85211181641\n",
      "148000 sentences dealed, loss: 2.8487200737\n",
      "149000 sentences dealed, loss: 3.34948968887\n",
      "150000 sentences dealed, loss: 3.20605015755\n",
      "151000 sentences dealed, loss: 3.7022330761\n",
      "152000 sentences dealed, loss: 3.51399183273\n",
      "153000 sentences dealed, loss: 2.95636749268\n",
      "154000 sentences dealed, loss: 2.82224869728\n",
      "155000 sentences dealed, loss: 3.21089792252\n",
      "156000 sentences dealed, loss: 3.5381667614\n",
      "157000 sentences dealed, loss: 3.29125070572\n",
      "158000 sentences dealed, loss: 3.40650320053\n",
      "159000 sentences dealed, loss: 3.14836168289\n",
      "160000 sentences dealed, loss: 3.21584248543\n",
      "161000 sentences dealed, loss: 2.96329188347\n",
      "162000 sentences dealed, loss: 3.26725625992\n",
      "163000 sentences dealed, loss: 2.9150853157\n",
      "164000 sentences dealed, loss: 2.82382059097\n",
      "165000 sentences dealed, loss: 2.96858716011\n",
      "166000 sentences dealed, loss: 3.15020442009\n",
      "167000 sentences dealed, loss: 3.1489443779\n",
      "168000 sentences dealed, loss: 3.02615118027\n",
      "169000 sentences dealed, loss: 3.22178888321\n",
      "170000 sentences dealed, loss: 3.13479804993\n",
      "171000 sentences dealed, loss: 3.32989001274\n",
      "172000 sentences dealed, loss: 3.15974807739\n",
      "173000 sentences dealed, loss: 2.75728869438\n",
      "174000 sentences dealed, loss: 3.12438464165\n",
      "175000 sentences dealed, loss: 2.99939966202\n",
      "176000 sentences dealed, loss: 3.0322663784\n",
      "177000 sentences dealed, loss: 3.25392198563\n",
      "178000 sentences dealed, loss: 2.86684560776\n",
      "179000 sentences dealed, loss: 3.0656042099\n",
      "180000 sentences dealed, loss: 3.17850351334\n",
      "181000 sentences dealed, loss: 2.90552282333\n",
      "182000 sentences dealed, loss: 3.01640558243\n",
      "183000 sentences dealed, loss: 3.10911130905\n",
      "184000 sentences dealed, loss: 3.16928648949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185000 sentences dealed, loss: 2.89502763748\n",
      "186000 sentences dealed, loss: 2.87102651596\n",
      "187000 sentences dealed, loss: 3.02389168739\n",
      "188000 sentences dealed, loss: 3.1589486599\n",
      "189000 sentences dealed, loss: 2.88454389572\n",
      "190000 sentences dealed, loss: 2.69530701637\n",
      "191000 sentences dealed, loss: 2.90977215767\n",
      "192000 sentences dealed, loss: 3.27319598198\n",
      "193000 sentences dealed, loss: 3.19958162308\n",
      "194000 sentences dealed, loss: 3.32260322571\n",
      "195000 sentences dealed, loss: 3.16411924362\n",
      "196000 sentences dealed, loss: 2.95315742493\n",
      "197000 sentences dealed, loss: 2.96916389465\n",
      "198000 sentences dealed, loss: 2.96893024445\n",
      "199000 sentences dealed, loss: 2.91722989082\n",
      "200000 sentences dealed, loss: 3.02858304977\n",
      "201000 sentences dealed, loss: 3.37296867371\n",
      "202000 sentences dealed, loss: 3.0125207901\n",
      "203000 sentences dealed, loss: 2.65308618546\n",
      "204000 sentences dealed, loss: 2.26431417465\n",
      "205000 sentences dealed, loss: 3.32464146614\n",
      "206000 sentences dealed, loss: 2.65362691879\n",
      "207000 sentences dealed, loss: 2.46785974503\n",
      "208000 sentences dealed, loss: 2.60143256187\n",
      "209000 sentences dealed, loss: 2.6637711525\n",
      "210000 sentences dealed, loss: 2.64326143265\n",
      "211000 sentences dealed, loss: 2.96973252296\n",
      "212000 sentences dealed, loss: 2.75363111496\n",
      "213000 sentences dealed, loss: 3.01842689514\n",
      "214000 sentences dealed, loss: 2.68739175797\n",
      "215000 sentences dealed, loss: 2.672270298\n",
      "216000 sentences dealed, loss: 2.69775128365\n",
      "217000 sentences dealed, loss: 2.4211640358\n",
      "218000 sentences dealed, loss: 2.69987869263\n",
      "219000 sentences dealed, loss: 2.48606324196\n",
      "220000 sentences dealed, loss: 3.03214001656\n",
      "221000 sentences dealed, loss: 2.35597753525\n",
      "222000 sentences dealed, loss: 2.92599272728\n",
      "223000 sentences dealed, loss: 2.96795272827\n",
      "224000 sentences dealed, loss: 2.59399318695\n",
      "225000 sentences dealed, loss: 2.45320320129\n",
      "226000 sentences dealed, loss: 2.577231884\n",
      "227000 sentences dealed, loss: 2.39133620262\n",
      "228000 sentences dealed, loss: 2.82630848885\n",
      "229000 sentences dealed, loss: 2.86977028847\n",
      "230000 sentences dealed, loss: 2.41062235832\n",
      "231000 sentences dealed, loss: 2.74566721916\n",
      "232000 sentences dealed, loss: 2.49978590012\n",
      "233000 sentences dealed, loss: 2.32164263725\n",
      "234000 sentences dealed, loss: 2.44969677925\n",
      "235000 sentences dealed, loss: 2.42730379105\n",
      "236000 sentences dealed, loss: 2.3918735981\n",
      "237000 sentences dealed, loss: 2.71556472778\n",
      "238000 sentences dealed, loss: 2.73279833794\n",
      "239000 sentences dealed, loss: 4.55125904083\n",
      "240000 sentences dealed, loss: 2.40428757668\n",
      "241000 sentences dealed, loss: 2.84040117264\n",
      "242000 sentences dealed, loss: 2.59528064728\n",
      "243000 sentences dealed, loss: 2.53448796272\n",
      "244000 sentences dealed, loss: 2.34031891823\n",
      "245000 sentences dealed, loss: 2.64452075958\n",
      "246000 sentences dealed, loss: 2.48963332176\n",
      "247000 sentences dealed, loss: 2.41688847542\n",
      "248000 sentences dealed, loss: 2.72852706909\n",
      "249000 sentences dealed, loss: 2.40175867081\n",
      "250000 sentences dealed, loss: 2.33446931839\n",
      "251000 sentences dealed, loss: 2.75881290436\n",
      "252000 sentences dealed, loss: 2.53791856766\n",
      "253000 sentences dealed, loss: 2.15092039108\n",
      "254000 sentences dealed, loss: 2.79585838318\n",
      "255000 sentences dealed, loss: 2.8428902626\n",
      "256000 sentences dealed, loss: 2.60777497292\n",
      "257000 sentences dealed, loss: 2.3176381588\n",
      "258000 sentences dealed, loss: 2.32782101631\n",
      "259000 sentences dealed, loss: 2.4115524292\n",
      "260000 sentences dealed, loss: 2.85358715057\n",
      "261000 sentences dealed, loss: 2.83663058281\n",
      "262000 sentences dealed, loss: 2.20799732208\n",
      "263000 sentences dealed, loss: 2.32654833794\n",
      "264000 sentences dealed, loss: 2.42401504517\n",
      "265000 sentences dealed, loss: 2.15042090416\n",
      "266000 sentences dealed, loss: 2.22090268135\n",
      "267000 sentences dealed, loss: 2.38159179688\n",
      "268000 sentences dealed, loss: 2.44969630241\n",
      "269000 sentences dealed, loss: 2.26761484146\n",
      "270000 sentences dealed, loss: 2.5051472187\n",
      "271000 sentences dealed, loss: 1.97525846958\n",
      "272000 sentences dealed, loss: 2.71867966652\n",
      "273000 sentences dealed, loss: 2.43753266335\n",
      "274000 sentences dealed, loss: 2.81949043274\n",
      "275000 sentences dealed, loss: 2.77981734276\n",
      "276000 sentences dealed, loss: 2.32345676422\n",
      "277000 sentences dealed, loss: 2.37251996994\n",
      "278000 sentences dealed, loss: 2.5914721489\n",
      "279000 sentences dealed, loss: 2.47776031494\n",
      "280000 sentences dealed, loss: 2.63260889053\n",
      "281000 sentences dealed, loss: 2.39818716049\n",
      "282000 sentences dealed, loss: 3.14443349838\n",
      "283000 sentences dealed, loss: 2.58481955528\n",
      "284000 sentences dealed, loss: 2.19185137749\n",
      "285000 sentences dealed, loss: 1.96911406517\n",
      "286000 sentences dealed, loss: 2.17784833908\n",
      "287000 sentences dealed, loss: 2.51924133301\n",
      "288000 sentences dealed, loss: 2.69723176956\n",
      "289000 sentences dealed, loss: 3.21201896667\n",
      "290000 sentences dealed, loss: 2.51001667976\n",
      "291000 sentences dealed, loss: 2.55908203125\n",
      "292000 sentences dealed, loss: 2.5160574913\n",
      "293000 sentences dealed, loss: 2.60448789597\n",
      "294000 sentences dealed, loss: 2.3615500927\n",
      "295000 sentences dealed, loss: 2.15727615356\n",
      "296000 sentences dealed, loss: 3.0811829567\n",
      "297000 sentences dealed, loss: 2.30263209343\n",
      "298000 sentences dealed, loss: 2.03040099144\n",
      "299000 sentences dealed, loss: 2.91929960251\n",
      "300000 sentences dealed, loss: 2.15672540665\n",
      "301000 sentences dealed, loss: 2.26907324791\n",
      "302000 sentences dealed, loss: 1.97974705696\n",
      "303000 sentences dealed, loss: 2.60820102692\n",
      "304000 sentences dealed, loss: 2.86199903488\n",
      "305000 sentences dealed, loss: 2.4683008194\n",
      "306000 sentences dealed, loss: 2.4827542305\n",
      "307000 sentences dealed, loss: 2.60385560989\n",
      "308000 sentences dealed, loss: 2.51148796082\n",
      "309000 sentences dealed, loss: 3.01290082932\n",
      "310000 sentences dealed, loss: 2.72579526901\n",
      "311000 sentences dealed, loss: 2.23237490654\n",
      "312000 sentences dealed, loss: 2.66210603714\n",
      "313000 sentences dealed, loss: 2.06095552444\n",
      "314000 sentences dealed, loss: 2.44584941864\n",
      "315000 sentences dealed, loss: 2.55237197876\n",
      "316000 sentences dealed, loss: 2.35834598541\n",
      "317000 sentences dealed, loss: 2.29270195961\n",
      "318000 sentences dealed, loss: 2.4071521759\n",
      "319000 sentences dealed, loss: 2.92041635513\n",
      "320000 sentences dealed, loss: 2.27069330215\n",
      "321000 sentences dealed, loss: 2.03722906113\n",
      "322000 sentences dealed, loss: 1.94075238705\n",
      "323000 sentences dealed, loss: 1.83898448944\n",
      "324000 sentences dealed, loss: 2.39409995079\n",
      "325000 sentences dealed, loss: 2.18404841423\n",
      "326000 sentences dealed, loss: 1.80735087395\n",
      "327000 sentences dealed, loss: 1.7507750988\n",
      "328000 sentences dealed, loss: 1.33709597588\n",
      "329000 sentences dealed, loss: 2.56282806396\n",
      "330000 sentences dealed, loss: 1.48719096184\n",
      "331000 sentences dealed, loss: 1.36699593067\n",
      "332000 sentences dealed, loss: 1.1091388464\n",
      "333000 sentences dealed, loss: 1.74329853058\n",
      "334000 sentences dealed, loss: 1.51983392239\n",
      "335000 sentences dealed, loss: 0.873618960381\n",
      "336000 sentences dealed, loss: 1.23757910728\n",
      "337000 sentences dealed, loss: 1.4607489109\n",
      "338000 sentences dealed, loss: 1.74224376678\n",
      "339000 sentences dealed, loss: 2.58326220512\n",
      "340000 sentences dealed, loss: 1.67831003666\n",
      "341000 sentences dealed, loss: 1.21069729328\n",
      "342000 sentences dealed, loss: 1.14520287514\n",
      "343000 sentences dealed, loss: 0.639860391617\n",
      "344000 sentences dealed, loss: 1.17304480076\n",
      "345000 sentences dealed, loss: 1.57250535488\n",
      "346000 sentences dealed, loss: 2.00595164299\n",
      "347000 sentences dealed, loss: 1.83441483974\n",
      "348000 sentences dealed, loss: 1.49413025379\n",
      "349000 sentences dealed, loss: 1.35819208622\n",
      "350000 sentences dealed, loss: 1.50691962242\n",
      "351000 sentences dealed, loss: 1.52598702908\n",
      "352000 sentences dealed, loss: 1.02592015266\n",
      "353000 sentences dealed, loss: 1.18034517765\n",
      "354000 sentences dealed, loss: 1.90947890282\n",
      "355000 sentences dealed, loss: 2.02519345284\n",
      "356000 sentences dealed, loss: 1.44215106964\n",
      "357000 sentences dealed, loss: 1.54024159908\n",
      "358000 sentences dealed, loss: 0.830104231834\n",
      "359000 sentences dealed, loss: 2.39766836166\n",
      "360000 sentences dealed, loss: 1.78320920467\n",
      "361000 sentences dealed, loss: 1.23263323307\n",
      "362000 sentences dealed, loss: 0.751542627811\n",
      "363000 sentences dealed, loss: 1.80488777161\n",
      "364000 sentences dealed, loss: 0.865618348122\n",
      "365000 sentences dealed, loss: 0.815764784813\n",
      "366000 sentences dealed, loss: 1.62652373314\n",
      "367000 sentences dealed, loss: 1.43639051914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368000 sentences dealed, loss: 1.75183558464\n",
      "369000 sentences dealed, loss: 1.16776549816\n",
      "370000 sentences dealed, loss: 1.59704661369\n",
      "371000 sentences dealed, loss: 1.75757443905\n",
      "372000 sentences dealed, loss: 1.68676304817\n",
      "373000 sentences dealed, loss: 1.33520317078\n",
      "374000 sentences dealed, loss: 1.65106928349\n",
      "375000 sentences dealed, loss: 1.47059953213\n",
      "376000 sentences dealed, loss: 1.27545464039\n",
      "377000 sentences dealed, loss: 0.974314033985\n",
      "378000 sentences dealed, loss: 1.40367519855\n",
      "379000 sentences dealed, loss: 0.850209832191\n",
      "380000 sentences dealed, loss: 1.47689330578\n",
      "381000 sentences dealed, loss: 1.62247526646\n",
      "382000 sentences dealed, loss: 1.12117123604\n",
      "383000 sentences dealed, loss: 1.40801918507\n",
      "384000 sentences dealed, loss: 1.79937744141\n",
      "385000 sentences dealed, loss: 1.10926568508\n",
      "386000 sentences dealed, loss: 1.648889184\n",
      "387000 sentences dealed, loss: 1.05383527279\n",
      "388000 sentences dealed, loss: 0.728933334351\n",
      "389000 sentences dealed, loss: 1.86671710014\n",
      "390000 sentences dealed, loss: 1.72987675667\n",
      "391000 sentences dealed, loss: 1.12635195255\n",
      "392000 sentences dealed, loss: 1.6083612442\n",
      "393000 sentences dealed, loss: 0.605641305447\n",
      "394000 sentences dealed, loss: 1.50789642334\n",
      "395000 sentences dealed, loss: 1.396895051\n",
      "396000 sentences dealed, loss: 1.36968064308\n",
      "397000 sentences dealed, loss: 1.56141293049\n",
      "398000 sentences dealed, loss: 1.27369475365\n",
      "399000 sentences dealed, loss: 1.89002680779\n",
      "400000 sentences dealed, loss: 0.697844624519\n",
      "401000 sentences dealed, loss: 0.964045226574\n",
      "402000 sentences dealed, loss: 1.49165606499\n",
      "403000 sentences dealed, loss: 1.06450796127\n",
      "404000 sentences dealed, loss: 1.03948271275\n",
      "405000 sentences dealed, loss: 1.07036662102\n",
      "406000 sentences dealed, loss: 1.24926543236\n",
      "407000 sentences dealed, loss: 1.12624502182\n",
      "408000 sentences dealed, loss: 1.15836703777\n",
      "409000 sentences dealed, loss: 1.76719379425\n",
      "410000 sentences dealed, loss: 0.524716496468\n",
      "411000 sentences dealed, loss: 1.10505104065\n",
      "412000 sentences dealed, loss: 2.37307858467\n",
      "413000 sentences dealed, loss: 0.767347157001\n",
      "414000 sentences dealed, loss: 1.22587668896\n",
      "415000 sentences dealed, loss: 1.62402129173\n",
      "416000 sentences dealed, loss: 1.81694638729\n",
      "417000 sentences dealed, loss: 2.24633097649\n",
      "418000 sentences dealed, loss: 0.989997208118\n",
      "419000 sentences dealed, loss: 1.74311482906\n",
      "420000 sentences dealed, loss: 1.2878510952\n",
      "421000 sentences dealed, loss: 0.966938614845\n",
      "422000 sentences dealed, loss: 1.48407292366\n",
      "423000 sentences dealed, loss: 0.994245052338\n",
      "424000 sentences dealed, loss: 0.698483943939\n",
      "425000 sentences dealed, loss: 1.64628505707\n",
      "426000 sentences dealed, loss: 0.943844616413\n",
      "427000 sentences dealed, loss: 1.23053371906\n",
      "428000 sentences dealed, loss: 1.33717477322\n",
      "429000 sentences dealed, loss: 1.32471168041\n",
      "430000 sentences dealed, loss: 1.46907043457\n",
      "431000 sentences dealed, loss: 1.03573858738\n",
      "432000 sentences dealed, loss: 0.810478210449\n",
      "433000 sentences dealed, loss: 0.535450875759\n",
      "434000 sentences dealed, loss: 0.980424046516\n",
      "435000 sentences dealed, loss: 1.21423387527\n",
      "436000 sentences dealed, loss: 1.2903854847\n",
      "437000 sentences dealed, loss: 1.4569631815\n",
      "438000 sentences dealed, loss: 0.68488907814\n",
      "439000 sentences dealed, loss: 0.59589445591\n",
      "440000 sentences dealed, loss: 1.67888355255\n",
      "441000 sentences dealed, loss: 0.975520312786\n",
      "442000 sentences dealed, loss: 0.808956325054\n",
      "443000 sentences dealed, loss: 1.9243503809\n",
      "444000 sentences dealed, loss: 0.659705102444\n",
      "445000 sentences dealed, loss: 1.05970931053\n",
      "446000 sentences dealed, loss: 1.12436807156\n",
      "447000 sentences dealed, loss: 1.83447289467\n",
      "448000 sentences dealed, loss: 0.974430918694\n",
      "449000 sentences dealed, loss: 1.51262235641\n",
      "450000 sentences dealed, loss: 1.45664954185\n",
      "451000 sentences dealed, loss: 1.46544086933\n",
      "452000 sentences dealed, loss: 2.19481372833\n",
      "453000 sentences dealed, loss: 1.46100580692\n",
      "454000 sentences dealed, loss: 1.12390303612\n",
      "455000 sentences dealed, loss: 1.73716473579\n",
      "456000 sentences dealed, loss: 0.974296092987\n",
      "457000 sentences dealed, loss: 1.9675668478\n",
      "458000 sentences dealed, loss: 0.737544298172\n",
      "459000 sentences dealed, loss: 1.05324614048\n",
      "460000 sentences dealed, loss: 0.917660355568\n",
      "461000 sentences dealed, loss: 1.16788578033\n",
      "462000 sentences dealed, loss: 1.59950089455\n",
      "463000 sentences dealed, loss: 1.61834084988\n",
      "464000 sentences dealed, loss: 1.3235193491\n",
      "465000 sentences dealed, loss: 0.885274529457\n",
      "466000 sentences dealed, loss: 1.41880381107\n",
      "467000 sentences dealed, loss: 1.86901533604\n",
      "468000 sentences dealed, loss: 1.25208294392\n",
      "469000 sentences dealed, loss: 1.01510739326\n",
      "470000 sentences dealed, loss: 1.12067580223\n",
      "471000 sentences dealed, loss: 0.808178901672\n",
      "472000 sentences dealed, loss: 1.10125255585\n",
      "473000 sentences dealed, loss: 1.68787312508\n",
      "474000 sentences dealed, loss: 1.54184484482\n",
      "475000 sentences dealed, loss: 1.30021429062\n",
      "476000 sentences dealed, loss: 0.732770502567\n",
      "477000 sentences dealed, loss: 1.63008117676\n",
      "478000 sentences dealed, loss: 0.924656271935\n",
      "479000 sentences dealed, loss: 0.644840478897\n",
      "480000 sentences dealed, loss: 1.4218224287\n",
      "481000 sentences dealed, loss: 1.5096218586\n",
      "482000 sentences dealed, loss: 1.48446333408\n",
      "483000 sentences dealed, loss: 0.948887348175\n",
      "484000 sentences dealed, loss: 1.03019988537\n",
      "485000 sentences dealed, loss: 1.20856499672\n",
      "486000 sentences dealed, loss: 1.06792914867\n",
      "487000 sentences dealed, loss: 1.67834889889\n",
      "488000 sentences dealed, loss: 1.67199730873\n",
      "489000 sentences dealed, loss: 1.18841433525\n",
      "490000 sentences dealed, loss: 0.534758925438\n",
      "491000 sentences dealed, loss: 3.08450078964\n",
      "492000 sentences dealed, loss: 2.67597842216\n",
      "493000 sentences dealed, loss: 2.55746197701\n",
      "494000 sentences dealed, loss: 2.52419662476\n",
      "495000 sentences dealed, loss: 2.54412746429\n",
      "496000 sentences dealed, loss: 2.7727227211\n",
      "497000 sentences dealed, loss: 2.57629275322\n",
      "498000 sentences dealed, loss: 2.61946368217\n",
      "499000 sentences dealed, loss: 2.7972073555\n",
      "500000 sentences dealed, loss: 2.61199712753\n",
      "501000 sentences dealed, loss: 2.72456932068\n",
      "502000 sentences dealed, loss: 2.62982225418\n",
      "503000 sentences dealed, loss: 2.57979536057\n",
      "504000 sentences dealed, loss: 2.73359751701\n",
      "505000 sentences dealed, loss: 2.69452357292\n",
      "506000 sentences dealed, loss: 2.86348056793\n",
      "507000 sentences dealed, loss: 2.73535060883\n",
      "508000 sentences dealed, loss: 2.85115480423\n",
      "509000 sentences dealed, loss: 2.85526967049\n",
      "510000 sentences dealed, loss: 2.85905623436\n",
      "511000 sentences dealed, loss: 2.76637411118\n",
      "512000 sentences dealed, loss: 2.73534822464\n",
      "513000 sentences dealed, loss: 2.57857871056\n",
      "514000 sentences dealed, loss: 2.79936289787\n",
      "515000 sentences dealed, loss: 2.93063020706\n",
      "516000 sentences dealed, loss: 2.93806910515\n",
      "517000 sentences dealed, loss: 2.7965900898\n",
      "518000 sentences dealed, loss: 3.02556657791\n",
      "519000 sentences dealed, loss: 2.77118515968\n",
      "520000 sentences dealed, loss: 2.49159550667\n",
      "521000 sentences dealed, loss: 2.77853631973\n",
      "522000 sentences dealed, loss: 2.93498873711\n",
      "523000 sentences dealed, loss: 2.93965768814\n",
      "524000 sentences dealed, loss: 2.30586504936\n",
      "525000 sentences dealed, loss: 2.57949614525\n",
      "526000 sentences dealed, loss: 2.61381530762\n",
      "527000 sentences dealed, loss: 2.92798018456\n",
      "528000 sentences dealed, loss: 2.55512571335\n",
      "529000 sentences dealed, loss: 2.84133672714\n",
      "530000 sentences dealed, loss: 2.87240362167\n",
      "531000 sentences dealed, loss: 2.77643585205\n",
      "532000 sentences dealed, loss: 2.87325143814\n",
      "533000 sentences dealed, loss: 2.84948945045\n",
      "534000 sentences dealed, loss: 3.11413097382\n",
      "535000 sentences dealed, loss: 2.93833780289\n",
      "536000 sentences dealed, loss: 2.69050765038\n",
      "537000 sentences dealed, loss: 2.81993842125\n",
      "538000 sentences dealed, loss: 2.86441087723\n",
      "539000 sentences dealed, loss: 2.71372580528\n",
      "540000 sentences dealed, loss: 2.51527452469\n",
      "541000 sentences dealed, loss: 3.05856776237\n",
      "542000 sentences dealed, loss: 2.42653131485\n",
      "543000 sentences dealed, loss: 2.67035317421\n",
      "544000 sentences dealed, loss: 2.56819224358\n",
      "545000 sentences dealed, loss: 3.42126536369\n",
      "546000 sentences dealed, loss: 2.99594426155\n",
      "547000 sentences dealed, loss: 2.5548312664\n",
      "548000 sentences dealed, loss: 2.62198519707\n",
      "549000 sentences dealed, loss: 3.10194087029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550000 sentences dealed, loss: 2.57941842079\n",
      "551000 sentences dealed, loss: 2.69429898262\n",
      "552000 sentences dealed, loss: 2.67031979561\n",
      "553000 sentences dealed, loss: 2.91149735451\n",
      "554000 sentences dealed, loss: 2.9244787693\n",
      "555000 sentences dealed, loss: 2.81034970284\n",
      "556000 sentences dealed, loss: 2.71847605705\n",
      "557000 sentences dealed, loss: 2.99836444855\n",
      "558000 sentences dealed, loss: 2.60815668106\n",
      "559000 sentences dealed, loss: 2.85789585114\n",
      "560000 sentences dealed, loss: 3.01768183708\n",
      "561000 sentences dealed, loss: 2.52918720245\n",
      "562000 sentences dealed, loss: 2.70776891708\n",
      "563000 sentences dealed, loss: 2.82660222054\n",
      "564000 sentences dealed, loss: 2.91375470161\n",
      "565000 sentences dealed, loss: 2.53144025803\n",
      "566000 sentences dealed, loss: 2.86877584457\n",
      "567000 sentences dealed, loss: 2.97989416122\n",
      "568000 sentences dealed, loss: 2.53290343285\n",
      "569000 sentences dealed, loss: 2.5851650238\n",
      "570000 sentences dealed, loss: 2.4205892086\n",
      "571000 sentences dealed, loss: 3.27186536789\n",
      "572000 sentences dealed, loss: 3.10258102417\n",
      "573000 sentences dealed, loss: 3.09466719627\n",
      "574000 sentences dealed, loss: 2.80156731606\n",
      "575000 sentences dealed, loss: 2.49701690674\n",
      "576000 sentences dealed, loss: 2.67408537865\n",
      "577000 sentences dealed, loss: 2.54337334633\n",
      "578000 sentences dealed, loss: 2.78653335571\n",
      "579000 sentences dealed, loss: 2.84559965134\n",
      "580000 sentences dealed, loss: 2.62317967415\n",
      "581000 sentences dealed, loss: 3.25488090515\n",
      "582000 sentences dealed, loss: 3.11999726295\n",
      "583000 sentences dealed, loss: 2.63658475876\n",
      "584000 sentences dealed, loss: 2.70507717133\n",
      "585000 sentences dealed, loss: 2.69221782684\n",
      "586000 sentences dealed, loss: 2.97637963295\n",
      "587000 sentences dealed, loss: 2.45531606674\n",
      "588000 sentences dealed, loss: 2.87687635422\n",
      "589000 sentences dealed, loss: 2.61295175552\n",
      "590000 sentences dealed, loss: 2.57538819313\n",
      "591000 sentences dealed, loss: 2.85695886612\n",
      "592000 sentences dealed, loss: 3.16941022873\n",
      "593000 sentences dealed, loss: 2.77662539482\n",
      "594000 sentences dealed, loss: 2.76379227638\n",
      "595000 sentences dealed, loss: 2.76969099045\n",
      "596000 sentences dealed, loss: 2.59644150734\n",
      "597000 sentences dealed, loss: 2.58733606339\n",
      "598000 sentences dealed, loss: 2.47014784813\n",
      "599000 sentences dealed, loss: 2.95828104019\n",
      "600000 sentences dealed, loss: 2.6254799366\n",
      "601000 sentences dealed, loss: 2.72016048431\n",
      "602000 sentences dealed, loss: 2.63477802277\n",
      "603000 sentences dealed, loss: 2.62990140915\n",
      "604000 sentences dealed, loss: 2.94445014\n",
      "605000 sentences dealed, loss: 2.62482094765\n",
      "606000 sentences dealed, loss: 2.34314441681\n",
      "607000 sentences dealed, loss: 2.66630768776\n",
      "608000 sentences dealed, loss: 2.42027306557\n",
      "609000 sentences dealed, loss: 2.45525503159\n",
      "610000 sentences dealed, loss: 2.51512265205\n",
      "611000 sentences dealed, loss: 2.70423388481\n",
      "612000 sentences dealed, loss: 2.75871372223\n",
      "613000 sentences dealed, loss: 3.45887708664\n",
      "614000 sentences dealed, loss: 3.04278993607\n",
      "615000 sentences dealed, loss: 2.80015707016\n",
      "616000 sentences dealed, loss: 3.07441663742\n",
      "617000 sentences dealed, loss: 2.93712615967\n",
      "618000 sentences dealed, loss: 3.01273584366\n",
      "619000 sentences dealed, loss: 3.01329231262\n",
      "620000 sentences dealed, loss: 3.0939655304\n",
      "621000 sentences dealed, loss: 3.74492120743\n",
      "622000 sentences dealed, loss: 3.029753685\n",
      "623000 sentences dealed, loss: 3.27636003494\n",
      "624000 sentences dealed, loss: 2.9924519062\n",
      "625000 sentences dealed, loss: 2.78908586502\n",
      "626000 sentences dealed, loss: 3.08920526505\n",
      "627000 sentences dealed, loss: 3.27049636841\n",
      "628000 sentences dealed, loss: 3.16486692429\n",
      "629000 sentences dealed, loss: 2.95858716965\n",
      "630000 sentences dealed, loss: 3.10306596756\n",
      "631000 sentences dealed, loss: 2.97553253174\n",
      "632000 sentences dealed, loss: 3.13953590393\n",
      "633000 sentences dealed, loss: 3.0410220623\n",
      "634000 sentences dealed, loss: 3.11109137535\n",
      "635000 sentences dealed, loss: 2.85034894943\n",
      "636000 sentences dealed, loss: 3.27168226242\n",
      "637000 sentences dealed, loss: 2.68938040733\n",
      "638000 sentences dealed, loss: 2.88003277779\n",
      "639000 sentences dealed, loss: 2.81316709518\n",
      "640000 sentences dealed, loss: 2.60457277298\n",
      "641000 sentences dealed, loss: 2.8757584095\n",
      "642000 sentences dealed, loss: 3.27573013306\n",
      "643000 sentences dealed, loss: 2.72612261772\n",
      "644000 sentences dealed, loss: 2.70787358284\n",
      "645000 sentences dealed, loss: 2.64452505112\n",
      "646000 sentences dealed, loss: 3.12934732437\n",
      "647000 sentences dealed, loss: 2.86715483665\n",
      "648000 sentences dealed, loss: 2.78269648552\n",
      "649000 sentences dealed, loss: 3.27713251114\n",
      "650000 sentences dealed, loss: 2.86814713478\n",
      "651000 sentences dealed, loss: 2.68891835213\n",
      "652000 sentences dealed, loss: 2.93695044518\n",
      "653000 sentences dealed, loss: 2.74020504951\n",
      "654000 sentences dealed, loss: 3.09387516975\n",
      "655000 sentences dealed, loss: 2.99233913422\n",
      "656000 sentences dealed, loss: 3.378292799\n",
      "657000 sentences dealed, loss: 2.7771961689\n",
      "658000 sentences dealed, loss: 3.02939605713\n",
      "659000 sentences dealed, loss: 3.32894515991\n",
      "660000 sentences dealed, loss: 3.19862174988\n",
      "661000 sentences dealed, loss: 3.09314727783\n",
      "662000 sentences dealed, loss: 3.20219111443\n",
      "663000 sentences dealed, loss: 3.46530079842\n",
      "664000 sentences dealed, loss: 3.07329702377\n",
      "665000 sentences dealed, loss: 3.06673836708\n",
      "666000 sentences dealed, loss: 3.00199699402\n",
      "667000 sentences dealed, loss: 2.90974760056\n",
      "668000 sentences dealed, loss: 2.72437143326\n",
      "669000 sentences dealed, loss: 2.95183253288\n",
      "670000 sentences dealed, loss: 3.09007310867\n",
      "671000 sentences dealed, loss: 3.24517297745\n",
      "672000 sentences dealed, loss: 2.84299898148\n",
      "673000 sentences dealed, loss: 3.08348822594\n",
      "674000 sentences dealed, loss: 3.2253575325\n",
      "675000 sentences dealed, loss: 3.37801027298\n",
      "676000 sentences dealed, loss: 3.16745066643\n",
      "677000 sentences dealed, loss: 2.78528547287\n",
      "678000 sentences dealed, loss: 2.80982637405\n",
      "679000 sentences dealed, loss: 3.16831731796\n",
      "680000 sentences dealed, loss: 2.96271896362\n",
      "681000 sentences dealed, loss: 2.87792682648\n",
      "682000 sentences dealed, loss: 2.81415104866\n",
      "683000 sentences dealed, loss: 2.75303173065\n",
      "684000 sentences dealed, loss: 2.79585909843\n",
      "685000 sentences dealed, loss: 2.71232318878\n",
      "686000 sentences dealed, loss: 2.90116333961\n",
      "687000 sentences dealed, loss: 2.94467663765\n",
      "688000 sentences dealed, loss: 2.89939928055\n",
      "689000 sentences dealed, loss: 3.07632493973\n",
      "690000 sentences dealed, loss: 2.86611294746\n",
      "691000 sentences dealed, loss: 3.16061782837\n",
      "692000 sentences dealed, loss: 2.28068971634\n",
      "693000 sentences dealed, loss: 2.88357257843\n",
      "694000 sentences dealed, loss: 2.47332596779\n",
      "695000 sentences dealed, loss: 2.65210771561\n",
      "696000 sentences dealed, loss: 2.38426351547\n",
      "697000 sentences dealed, loss: 2.49640130997\n",
      "698000 sentences dealed, loss: 2.89650011063\n",
      "699000 sentences dealed, loss: 2.40411353111\n",
      "700000 sentences dealed, loss: 2.24420928955\n",
      "701000 sentences dealed, loss: 2.33409619331\n",
      "702000 sentences dealed, loss: 2.24205827713\n",
      "703000 sentences dealed, loss: 2.39581608772\n",
      "704000 sentences dealed, loss: 2.27113103867\n",
      "705000 sentences dealed, loss: 1.96976447105\n",
      "706000 sentences dealed, loss: 2.81287240982\n",
      "707000 sentences dealed, loss: 2.4258556366\n",
      "708000 sentences dealed, loss: 2.486941576\n",
      "709000 sentences dealed, loss: 1.98765921593\n",
      "710000 sentences dealed, loss: 2.36652469635\n",
      "711000 sentences dealed, loss: 2.18708205223\n",
      "712000 sentences dealed, loss: 2.3444507122\n",
      "713000 sentences dealed, loss: 2.60882997513\n",
      "714000 sentences dealed, loss: 2.49579882622\n",
      "715000 sentences dealed, loss: 2.01820516586\n",
      "716000 sentences dealed, loss: 2.2079501152\n",
      "717000 sentences dealed, loss: 2.07805490494\n",
      "718000 sentences dealed, loss: 2.5506002903\n",
      "719000 sentences dealed, loss: 2.81904387474\n",
      "720000 sentences dealed, loss: 2.47029662132\n",
      "721000 sentences dealed, loss: 2.33591508865\n",
      "722000 sentences dealed, loss: 1.94589400291\n",
      "723000 sentences dealed, loss: 2.17134189606\n",
      "724000 sentences dealed, loss: 2.29865884781\n",
      "725000 sentences dealed, loss: 2.36590266228\n",
      "726000 sentences dealed, loss: 2.218501091\n",
      "727000 sentences dealed, loss: 2.17164468765\n",
      "728000 sentences dealed, loss: 2.78598332405\n",
      "729000 sentences dealed, loss: 2.22221446037\n",
      "730000 sentences dealed, loss: 2.35520601273\n",
      "731000 sentences dealed, loss: 2.14482736588\n",
      "732000 sentences dealed, loss: 2.29487085342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733000 sentences dealed, loss: 2.3186173439\n",
      "734000 sentences dealed, loss: 2.79251813889\n",
      "735000 sentences dealed, loss: 2.31188726425\n",
      "736000 sentences dealed, loss: 2.3840174675\n",
      "737000 sentences dealed, loss: 2.46898078918\n",
      "738000 sentences dealed, loss: 2.64057207108\n",
      "739000 sentences dealed, loss: 2.09118795395\n",
      "740000 sentences dealed, loss: 2.50765562057\n",
      "741000 sentences dealed, loss: 2.14096498489\n",
      "742000 sentences dealed, loss: 2.74138998985\n",
      "743000 sentences dealed, loss: 2.45979809761\n",
      "744000 sentences dealed, loss: 2.68458628654\n",
      "745000 sentences dealed, loss: 1.8776652813\n",
      "746000 sentences dealed, loss: 2.52517604828\n",
      "747000 sentences dealed, loss: 2.19527935982\n",
      "748000 sentences dealed, loss: 1.77589154243\n",
      "749000 sentences dealed, loss: 2.22947788239\n",
      "750000 sentences dealed, loss: 2.63180589676\n",
      "751000 sentences dealed, loss: 2.32637214661\n",
      "752000 sentences dealed, loss: 2.65154051781\n",
      "753000 sentences dealed, loss: 2.21066522598\n",
      "754000 sentences dealed, loss: 2.47215390205\n",
      "755000 sentences dealed, loss: 2.46853756905\n",
      "756000 sentences dealed, loss: 1.93692719936\n",
      "757000 sentences dealed, loss: 2.38604998589\n",
      "758000 sentences dealed, loss: 2.3250246048\n",
      "759000 sentences dealed, loss: 2.32008886337\n",
      "760000 sentences dealed, loss: 1.9340133667\n",
      "761000 sentences dealed, loss: 2.52049088478\n",
      "762000 sentences dealed, loss: 2.22327899933\n",
      "763000 sentences dealed, loss: 2.02415466309\n",
      "764000 sentences dealed, loss: 1.95571899414\n",
      "765000 sentences dealed, loss: 2.33181023598\n",
      "766000 sentences dealed, loss: 2.13555240631\n",
      "767000 sentences dealed, loss: 1.57566154003\n",
      "768000 sentences dealed, loss: 1.9661642313\n",
      "769000 sentences dealed, loss: 2.71023869514\n",
      "770000 sentences dealed, loss: 2.02724909782\n",
      "771000 sentences dealed, loss: 2.25256228447\n",
      "772000 sentences dealed, loss: 2.67434430122\n",
      "773000 sentences dealed, loss: 2.32397150993\n",
      "774000 sentences dealed, loss: 2.04804182053\n",
      "775000 sentences dealed, loss: 2.18978953362\n",
      "776000 sentences dealed, loss: 2.0360314846\n",
      "777000 sentences dealed, loss: 2.00157475471\n",
      "778000 sentences dealed, loss: 2.5367667675\n",
      "779000 sentences dealed, loss: 2.30959606171\n",
      "780000 sentences dealed, loss: 2.53157663345\n",
      "781000 sentences dealed, loss: 2.1517572403\n",
      "782000 sentences dealed, loss: 2.20100402832\n",
      "783000 sentences dealed, loss: 2.52755856514\n",
      "784000 sentences dealed, loss: 1.89516377449\n",
      "785000 sentences dealed, loss: 2.17071294785\n",
      "786000 sentences dealed, loss: 2.73788571358\n",
      "787000 sentences dealed, loss: 3.04354572296\n",
      "788000 sentences dealed, loss: 2.33068060875\n",
      "789000 sentences dealed, loss: 2.04803347588\n",
      "790000 sentences dealed, loss: 1.63544404507\n",
      "791000 sentences dealed, loss: 2.2919344902\n",
      "792000 sentences dealed, loss: 2.06732273102\n",
      "793000 sentences dealed, loss: 2.05459451675\n",
      "794000 sentences dealed, loss: 2.31738233566\n",
      "795000 sentences dealed, loss: 2.35295915604\n",
      "796000 sentences dealed, loss: 2.47440862656\n",
      "797000 sentences dealed, loss: 2.28869533539\n",
      "798000 sentences dealed, loss: 2.15354824066\n",
      "799000 sentences dealed, loss: 2.04951047897\n",
      "800000 sentences dealed, loss: 2.70561313629\n",
      "801000 sentences dealed, loss: 2.24931049347\n",
      "802000 sentences dealed, loss: 2.4814119339\n",
      "803000 sentences dealed, loss: 1.99553704262\n",
      "804000 sentences dealed, loss: 2.12594676018\n",
      "805000 sentences dealed, loss: 2.34181308746\n",
      "806000 sentences dealed, loss: 2.24901819229\n",
      "807000 sentences dealed, loss: 1.94677186012\n",
      "808000 sentences dealed, loss: 2.34735584259\n",
      "809000 sentences dealed, loss: 2.19059324265\n",
      "810000 sentences dealed, loss: 2.21852278709\n",
      "811000 sentences dealed, loss: 2.5490424633\n",
      "812000 sentences dealed, loss: 0.979628384113\n",
      "813000 sentences dealed, loss: 1.10431468487\n",
      "814000 sentences dealed, loss: 1.21086966991\n",
      "815000 sentences dealed, loss: 1.93965244293\n",
      "816000 sentences dealed, loss: 1.03332209587\n",
      "817000 sentences dealed, loss: 1.3868612051\n",
      "818000 sentences dealed, loss: 0.956607460976\n",
      "819000 sentences dealed, loss: 1.07821321487\n",
      "820000 sentences dealed, loss: 0.943298637867\n",
      "821000 sentences dealed, loss: 0.889418721199\n",
      "822000 sentences dealed, loss: 1.3195567131\n",
      "823000 sentences dealed, loss: 1.14325940609\n",
      "824000 sentences dealed, loss: 1.35978710651\n",
      "825000 sentences dealed, loss: 1.35789561272\n",
      "826000 sentences dealed, loss: 0.909390449524\n",
      "827000 sentences dealed, loss: 1.00754666328\n",
      "828000 sentences dealed, loss: 1.2195584774\n",
      "829000 sentences dealed, loss: 0.73268020153\n",
      "830000 sentences dealed, loss: 1.36415719986\n",
      "831000 sentences dealed, loss: 0.777392268181\n",
      "832000 sentences dealed, loss: 0.941188931465\n",
      "833000 sentences dealed, loss: 1.25800728798\n",
      "834000 sentences dealed, loss: 1.08768713474\n",
      "835000 sentences dealed, loss: 1.55639600754\n",
      "836000 sentences dealed, loss: 1.50779235363\n",
      "837000 sentences dealed, loss: 1.20916736126\n",
      "838000 sentences dealed, loss: 1.62204480171\n",
      "839000 sentences dealed, loss: 1.47031378746\n",
      "840000 sentences dealed, loss: 1.56864154339\n",
      "841000 sentences dealed, loss: 1.66575932503\n",
      "842000 sentences dealed, loss: 1.03712916374\n",
      "843000 sentences dealed, loss: 1.55620205402\n",
      "844000 sentences dealed, loss: 1.41570675373\n",
      "845000 sentences dealed, loss: 1.16309726238\n",
      "846000 sentences dealed, loss: 1.27361226082\n",
      "847000 sentences dealed, loss: 1.03375601768\n",
      "848000 sentences dealed, loss: 0.567954242229\n",
      "849000 sentences dealed, loss: 1.14701735973\n",
      "850000 sentences dealed, loss: 1.14314687252\n",
      "851000 sentences dealed, loss: 0.990492641926\n",
      "852000 sentences dealed, loss: 1.19729316235\n",
      "853000 sentences dealed, loss: 0.678627371788\n",
      "854000 sentences dealed, loss: 1.02924764156\n",
      "855000 sentences dealed, loss: 0.899159312248\n",
      "856000 sentences dealed, loss: 1.82390999794\n",
      "857000 sentences dealed, loss: 1.42790126801\n",
      "858000 sentences dealed, loss: 0.624821484089\n",
      "859000 sentences dealed, loss: 0.7713149786\n",
      "860000 sentences dealed, loss: 1.80730783939\n",
      "861000 sentences dealed, loss: 1.09894931316\n",
      "862000 sentences dealed, loss: 1.5249735117\n",
      "863000 sentences dealed, loss: 1.25956594944\n",
      "864000 sentences dealed, loss: 1.29722952843\n",
      "865000 sentences dealed, loss: 1.39437794685\n",
      "866000 sentences dealed, loss: 1.12762367725\n",
      "867000 sentences dealed, loss: 1.67786192894\n",
      "868000 sentences dealed, loss: 1.25826716423\n",
      "869000 sentences dealed, loss: 0.93074131012\n",
      "870000 sentences dealed, loss: 1.24512791634\n",
      "871000 sentences dealed, loss: 0.939159870148\n",
      "872000 sentences dealed, loss: 0.823369681835\n",
      "873000 sentences dealed, loss: 1.1417658329\n",
      "874000 sentences dealed, loss: 0.999679386616\n",
      "875000 sentences dealed, loss: 1.22035527229\n",
      "876000 sentences dealed, loss: 0.708641529083\n",
      "877000 sentences dealed, loss: 1.68542826176\n",
      "878000 sentences dealed, loss: 1.59002411366\n",
      "879000 sentences dealed, loss: 1.5835340023\n",
      "880000 sentences dealed, loss: 0.866747677326\n",
      "881000 sentences dealed, loss: 1.0652140379\n",
      "882000 sentences dealed, loss: 1.27849125862\n",
      "883000 sentences dealed, loss: 1.11925816536\n",
      "884000 sentences dealed, loss: 1.49013900757\n",
      "885000 sentences dealed, loss: 1.49897515774\n",
      "886000 sentences dealed, loss: 1.68097805977\n",
      "887000 sentences dealed, loss: 1.00075888634\n",
      "888000 sentences dealed, loss: 0.923477470875\n",
      "889000 sentences dealed, loss: 1.01159107685\n",
      "890000 sentences dealed, loss: 0.731096446514\n",
      "891000 sentences dealed, loss: 1.38353538513\n",
      "892000 sentences dealed, loss: 0.789974987507\n",
      "893000 sentences dealed, loss: 1.6066467762\n",
      "894000 sentences dealed, loss: 0.969335436821\n",
      "895000 sentences dealed, loss: 0.453654438257\n",
      "896000 sentences dealed, loss: 1.7251342535\n",
      "897000 sentences dealed, loss: 0.898919224739\n",
      "898000 sentences dealed, loss: 1.26394450665\n",
      "899000 sentences dealed, loss: 1.30370163918\n",
      "900000 sentences dealed, loss: 0.939654946327\n",
      "901000 sentences dealed, loss: 1.34195387363\n",
      "902000 sentences dealed, loss: 1.93976783752\n",
      "903000 sentences dealed, loss: 0.709721386433\n",
      "904000 sentences dealed, loss: 0.905047059059\n",
      "905000 sentences dealed, loss: 1.34399473667\n",
      "906000 sentences dealed, loss: 1.0146971941\n",
      "907000 sentences dealed, loss: 1.52581119537\n",
      "908000 sentences dealed, loss: 0.816277980804\n",
      "909000 sentences dealed, loss: 1.25301039219\n",
      "910000 sentences dealed, loss: 1.20836949348\n",
      "911000 sentences dealed, loss: 1.23078417778\n",
      "912000 sentences dealed, loss: 1.12080490589\n",
      "913000 sentences dealed, loss: 1.7217772007\n",
      "914000 sentences dealed, loss: 1.85862231255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915000 sentences dealed, loss: 1.57037270069\n",
      "916000 sentences dealed, loss: 1.27569937706\n",
      "917000 sentences dealed, loss: 0.601967275143\n",
      "918000 sentences dealed, loss: 1.18414473534\n",
      "919000 sentences dealed, loss: 1.31255269051\n",
      "920000 sentences dealed, loss: 0.780288159847\n",
      "921000 sentences dealed, loss: 0.830997645855\n",
      "922000 sentences dealed, loss: 1.33247625828\n",
      "923000 sentences dealed, loss: 1.53611671925\n",
      "924000 sentences dealed, loss: 1.31761789322\n",
      "925000 sentences dealed, loss: 1.40636563301\n",
      "926000 sentences dealed, loss: 1.16915416718\n",
      "927000 sentences dealed, loss: 1.04609584808\n",
      "928000 sentences dealed, loss: 1.32991051674\n",
      "929000 sentences dealed, loss: 0.711790978909\n",
      "930000 sentences dealed, loss: 0.305884212255\n",
      "931000 sentences dealed, loss: 1.16384208202\n",
      "932000 sentences dealed, loss: 1.57277071476\n",
      "933000 sentences dealed, loss: 0.924256026745\n",
      "934000 sentences dealed, loss: 1.41814887524\n",
      "935000 sentences dealed, loss: 1.41026699543\n",
      "936000 sentences dealed, loss: 1.6938803196\n",
      "937000 sentences dealed, loss: 1.59367620945\n",
      "938000 sentences dealed, loss: 1.37313091755\n",
      "939000 sentences dealed, loss: 1.38232409954\n",
      "940000 sentences dealed, loss: 1.93835699558\n",
      "941000 sentences dealed, loss: 1.75411915779\n",
      "942000 sentences dealed, loss: 1.01731240749\n",
      "943000 sentences dealed, loss: 1.11226725578\n",
      "944000 sentences dealed, loss: 0.41472324729\n",
      "945000 sentences dealed, loss: 1.01961410046\n",
      "946000 sentences dealed, loss: 1.02842485905\n",
      "947000 sentences dealed, loss: 0.725794911385\n",
      "948000 sentences dealed, loss: 1.17763614655\n",
      "949000 sentences dealed, loss: 1.42974352837\n",
      "950000 sentences dealed, loss: 1.25346744061\n",
      "951000 sentences dealed, loss: 1.03047978878\n",
      "952000 sentences dealed, loss: 1.36177933216\n",
      "953000 sentences dealed, loss: 1.93212223053\n",
      "954000 sentences dealed, loss: 1.11396002769\n",
      "955000 sentences dealed, loss: 0.844871222973\n",
      "956000 sentences dealed, loss: 1.0113748312\n",
      "957000 sentences dealed, loss: 0.851227939129\n",
      "958000 sentences dealed, loss: 1.03575921059\n",
      "959000 sentences dealed, loss: 1.21616816521\n",
      "960000 sentences dealed, loss: 0.890468239784\n",
      "961000 sentences dealed, loss: 1.42906761169\n",
      "962000 sentences dealed, loss: 1.71545219421\n",
      "963000 sentences dealed, loss: 1.34120798111\n",
      "964000 sentences dealed, loss: 1.19278383255\n",
      "965000 sentences dealed, loss: 1.34639155865\n",
      "966000 sentences dealed, loss: 1.75675010681\n",
      "967000 sentences dealed, loss: 1.5173586607\n",
      "968000 sentences dealed, loss: 0.988300919533\n",
      "969000 sentences dealed, loss: 1.54112696648\n",
      "970000 sentences dealed, loss: 0.786465287209\n",
      "971000 sentences dealed, loss: 0.666486859322\n",
      "972000 sentences dealed, loss: 1.24328005314\n",
      "973000 sentences dealed, loss: 1.03736042976\n",
      "974000 sentences dealed, loss: 1.2026964426\n",
      "975000 sentences dealed, loss: 1.02875435352\n",
      "976000 sentences dealed, loss: 1.48743081093\n",
      "977000 sentences dealed, loss: 1.62688064575\n",
      "978000 sentences dealed, loss: 1.34318089485\n",
      "979000 sentences dealed, loss: 0.928327918053\n",
      "980000 sentences dealed, loss: 1.14064621925\n",
      "981000 sentences dealed, loss: 3.2105910778\n",
      "982000 sentences dealed, loss: 2.8032450676\n",
      "983000 sentences dealed, loss: 3.05660772324\n",
      "984000 sentences dealed, loss: 3.10890007019\n",
      "985000 sentences dealed, loss: 3.14528369904\n",
      "986000 sentences dealed, loss: 2.8758392334\n",
      "987000 sentences dealed, loss: 2.82636404037\n",
      "988000 sentences dealed, loss: 3.15007328987\n",
      "989000 sentences dealed, loss: 2.70921897888\n",
      "990000 sentences dealed, loss: 2.91834449768\n",
      "991000 sentences dealed, loss: 2.75997662544\n",
      "992000 sentences dealed, loss: 2.66138291359\n",
      "993000 sentences dealed, loss: 2.82035422325\n",
      "994000 sentences dealed, loss: 2.92032599449\n",
      "995000 sentences dealed, loss: 2.63397860527\n",
      "996000 sentences dealed, loss: 3.07537031174\n",
      "997000 sentences dealed, loss: 2.70962429047\n",
      "998000 sentences dealed, loss: 2.92915964127\n",
      "999000 sentences dealed, loss: 2.57943201065\n",
      "[[u'\\u6444', u'\\u50cf', u'\\u7d20', u'\\u96c6', u'\\u6210', u'\\u89e6', u'\\u566a', u'\\u53d9', u'\\u5149', u'\\u5f0f'], [u'\\u5f98', u'\\u901a', u'\\u82a6', u'\\u673a', u'\\u6d2a', u'\\u7280', u'\\u6765', u'\\u8d1d', u'\\u6a58', u'\\u5f90'], [u'\\u76f8', u'\\u4e4e', u'\\u624b', u'\\u732b', u'\\u56a3', u'\\u7280', u'\\u51b0', u'\\u52a8', u'\\u4f9d', u'\\u77ee'], [u'\\u96c4', u'\\u62c5', u'\\u7529', u'\\u6d9b', u'\\u6e7f', u'\\u892a', u'\\u5ba0', u'\\u5c45', u'\\u906e', u'\\u96ea'], [u'\\u9175', u'\\u5170', u'\\u6234', u'\\u9ea6', u'\\u5b8f', u'\\u5254', u'\\u888b', u'\\u5c3c', u'\\u6797', u'\\u8c6a'], [u'\\u4e52', u'\\u706b', u'\\u8d54', u'\\u8d1d', u'\\u8fed', u'\\u8c10', u'\\u68da', u'\\u66a8', u'\\u5168', u'\\u4f7c'], [u'\\u65c5', u'\\u5a7f', u'\\u53bf', u'\\u77bb', u'\\u5ea6', u'\\u8574', u'\\u6d45', u'\\u731c', u'\\u521b', u'\\u51b7'], [u'\\u8882', u'\\u9501', u'\\u5f80', u'\\u9986', u'\\u4fc3', u'\\u99a5', u'\\u5e7d', u'\\u59e5', u'\\u5c0f', u'\\u589e'], [u'\\u4e1a', u'\\u65e6', u'\\u7c41', u'\\u71d5', u'\\u8001', u'\\u4e4b', u'\\u65fa', u'\\u95f7', u'\\u521b', u'\\u65e8'], [u'\\u822a', u'\\u5c38', u'\\u5bf8', u'\\u96c1', u'\\u73ba', u'\\u8d2c', u'\\u62d0', u'\\u9cb8', u'\\u6d47', u'\\u9648'], [u'\\u738b', u'\\u7f8e', u'\\u4e24', u'\\u65ec', u'\\u9009', u'\\u6bd4', u'\\u68cb', u'\\u8f76', u'\\u62ff', u'\\u73b0'], [u'\\u6c5f', u'\\u4f3d', u'\\u9a70', u'\\u6512', u'\\u5a01', u'\\u51bb', u'\\u6324', u'\\u897f', u'\\u6148', u'\\u7948'], [u'\\u676d', u'\\u964d', u'\\u518d', u'\\u5f84', u'\\u5802', u'\\u5907', u'\\u573a', u'\\u9501', u'\\u5f3a', u'\\u961f'], [u'\\u72c2', u'\\u722c', u'\\u5438', u'\\u5236', u'\\u88c1', u'\\u67f1', u'\\u8058', u'\\u8bf1', u'\\u4ed8', u'\\u9f50'], [u'\\u53ee', u'\\u4e27', u'\\u95f7', u'\\u77f3', u'\\u6d25', u'\\u4e13', u'\\u9b4f', u'\\u4fc3', u'\\u8155', u'\\u8c31'], [u'\\u7ad9', u'\\u5e02', u'\\u79fb', u'\\u5428', u'\\u533a', u'\\u94fa', u'\\u8be2', u'\\u65a4', u'\\u71d5', u'\\u6e7f'], [u'\\u3002', u'\\uff0c', u'\\u662f', u'\\u4e86', u'\\u961f', u'\\u800c', u'\\u548c', u'\\u5bf9', u'\\u4ece', u'\\u4e4b'], [u'\\u58a8', u'\\u5c55', u'\\u9650', u'\\u7ad9', u'\\u71a0', u'\\u5200', u'\\u8fd4', u'\\u5b37', u'\\u9053', u'\\u5415'], [u'\\u75be', u'\\u8475', u'\\u7099', u'\\u6bd2', u'\\u4e8b', u'\\u529e', u'\\u63a9', u'\\u5c11', u'\\u544a', u'\\u62b9'], [u'\\u6a2a', u'\\u4e61', u'\\u79cd', u'\\u9893', u'\\u62a4', u'\\u5708', u'\\u64ce', u'\\u8f70', u'\\u5e0c', u'\\u7aef']]\n",
      "头\n",
      "('\\xe6\\x91\\x84 \\xe5\\x83\\x8f', '\\xe7\\xb4\\xa0', '\\xe9\\x9b\\x86', '\\xe6\\x88\\x90', '\\xe8\\xa7\\xa6', '\\xe5\\x99\\xaa', '\\xe5\\x99\\xaa')\n",
      "手\n",
      "('\\xe5\\xbe\\x98 \\xe9\\x80\\x9a', '\\xe8\\x8a\\xa6', '\\xe6\\x9c\\xba', '\\xe6\\xb4\\xaa', '\\xe7\\x8a\\x80', '\\xe6\\x9d\\xa5', '\\xe6\\x9d\\xa5')\n",
      "机\n",
      "('\\xe7\\x9b\\xb8 \\xe4\\xb9\\x8e', '\\xe6\\x89\\x8b', '\\xe7\\x8c\\xab', '\\xe5\\x9a\\xa3', '\\xe7\\x8a\\x80', '\\xe5\\x86\\xb0', '\\xe5\\x86\\xb0')\n",
      "长\n",
      "('\\xe9\\x9b\\x84 \\xe6\\x8b\\x85', '\\xe7\\x94\\xa9', '\\xe6\\xb6\\x9b', '\\xe6\\xb9\\xbf', '\\xe8\\xa4\\xaa', '\\xe5\\xae\\xa0', '\\xe5\\xae\\xa0')\n",
      "尊\n",
      "('\\xe9\\x85\\xb5 \\xe5\\x85\\xb0', '\\xe6\\x88\\xb4', '\\xe9\\xba\\xa6', '\\xe5\\xae\\x8f', '\\xe5\\x89\\x94', '\\xe8\\xa2\\x8b', '\\xe8\\xa2\\x8b')\n",
      "皱\n",
      "('\\xe4\\xb9\\x92 \\xe7\\x81\\xab', '\\xe8\\xb5\\x94', '\\xe8\\xb4\\x9d', '\\xe8\\xbf\\xad', '\\xe8\\xb0\\x90', '\\xe6\\xa3\\x9a', '\\xe6\\xa3\\x9a')\n",
      "吃\n",
      "('\\xe6\\x97\\x85 \\xe5\\xa9\\xbf', '\\xe5\\x8e\\xbf', '\\xe7\\x9e\\xbb', '\\xe5\\xba\\xa6', '\\xe8\\x95\\xb4', '\\xe6\\xb5\\x85', '\\xe6\\xb5\\x85')\n",
      "喝\n",
      "('\\xe8\\xa2\\x82 \\xe9\\x94\\x81', '\\xe5\\xbe\\x80', '\\xe9\\xa6\\x86', '\\xe4\\xbf\\x83', '\\xe9\\xa6\\xa5', '\\xe5\\xb9\\xbd', '\\xe5\\xb9\\xbd')\n",
      "中\n",
      "('\\xe4\\xb8\\x9a \\xe6\\x97\\xa6', '\\xe7\\xb1\\x81', '\\xe7\\x87\\x95', '\\xe8\\x80\\x81', '\\xe4\\xb9\\x8b', '\\xe6\\x97\\xba', '\\xe6\\x97\\xba')\n",
      "英\n",
      "('\\xe8\\x88\\xaa \\xe5\\xb0\\xb8', '\\xe5\\xaf\\xb8', '\\xe9\\x9b\\x81', '\\xe7\\x8e\\xba', '\\xe8\\xb4\\xac', '\\xe6\\x8b\\x90', '\\xe6\\x8b\\x90')\n",
      "胜\n",
      "('\\xe7\\x8e\\x8b \\xe7\\xbe\\x8e', '\\xe4\\xb8\\xa4', '\\xe6\\x97\\xac', '\\xe9\\x80\\x89', '\\xe6\\xaf\\x94', '\\xe6\\xa3\\x8b', '\\xe6\\xa3\\x8b')\n",
      "东\n",
      "('\\xe6\\xb1\\x9f \\xe4\\xbc\\xbd', '\\xe9\\xa9\\xb0', '\\xe6\\x94\\x92', '\\xe5\\xa8\\x81', '\\xe5\\x86\\xbb', '\\xe6\\x8c\\xa4', '\\xe6\\x8c\\xa4')\n",
      "男\n",
      "('\\xe6\\x9d\\xad \\xe9\\x99\\x8d', '\\xe5\\x86\\x8d', '\\xe5\\xbe\\x84', '\\xe5\\xa0\\x82', '\\xe5\\xa4\\x87', '\\xe5\\x9c\\xba', '\\xe5\\x9c\\xba')\n",
      "蓝\n",
      "('\\xe7\\x8b\\x82 \\xe7\\x88\\xac', '\\xe5\\x90\\xb8', '\\xe5\\x88\\xb6', '\\xe8\\xa3\\x81', '\\xe6\\x9f\\xb1', '\\xe8\\x81\\x98', '\\xe8\\x81\\x98')\n",
      "南\n",
      "('\\xe5\\x8f\\xae \\xe4\\xb8\\xa7', '\\xe9\\x97\\xb7', '\\xe7\\x9f\\xb3', '\\xe6\\xb4\\xa5', '\\xe4\\xb8\\x93', '\\xe9\\xad\\x8f', '\\xe9\\xad\\x8f')\n",
      "地\n",
      "('\\xe7\\xab\\x99 \\xe5\\xb8\\x82', '\\xe7\\xa7\\xbb', '\\xe5\\x90\\xa8', '\\xe5\\x8c\\xba', '\\xe9\\x93\\xba', '\\xe8\\xaf\\xa2', '\\xe8\\xaf\\xa2')\n",
      "的\n",
      "('\\xe3\\x80\\x82 \\xef\\xbc\\x8c', '\\xe6\\x98\\xaf', '\\xe4\\xba\\x86', '\\xe9\\x98\\x9f', '\\xe8\\x80\\x8c', '\\xe5\\x92\\x8c', '\\xe5\\x92\\x8c')\n",
      "育\n",
      "('\\xe5\\xa2\\xa8 \\xe5\\xb1\\x95', '\\xe9\\x99\\x90', '\\xe7\\xab\\x99', '\\xe7\\x86\\xa0', '\\xe5\\x88\\x80', '\\xe8\\xbf\\x94', '\\xe8\\xbf\\x94')\n",
      "酒\n",
      "('\\xe7\\x96\\xbe \\xe8\\x91\\xb5', '\\xe7\\x82\\x99', '\\xe6\\xaf\\x92', '\\xe4\\xba\\x8b', '\\xe5\\x8a\\x9e', '\\xe6\\x8e\\xa9', '\\xe6\\x8e\\xa9')\n",
      "救\n",
      "('\\xe6\\xa8\\xaa \\xe4\\xb9\\xa1', '\\xe7\\xa7\\x8d', '\\xe9\\xa2\\x93', '\\xe6\\x8a\\xa4', '\\xe5\\x9c\\x88', '\\xe6\\x93\\x8e', '\\xe6\\x93\\x8e')\n",
      "6756\n",
      "6756\n",
      "<type 'list'>\n",
      "6756\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import collections\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "import re\n",
    "import os.path as path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "learn_rate    = 0.05\n",
    "embedding_size=16\n",
    "window_size=4\n",
    "\n",
    "class word2vec():\n",
    "    def __init__(self,\n",
    "                 vocab_list=None,\n",
    "                 embedding_size=embedding_size,\n",
    "                 win_len=window_size, # 单边窗口长\n",
    "                 num_sampled=1000,\n",
    "                 learning_rate=1.0,\n",
    "                 logdir='/tmp/simple_word2vec',\n",
    "                 model_path= None\n",
    "                 ):\n",
    "\n",
    "        # 获得模型的基本参数\n",
    "        self.batch_size     = None # 一批中数据个数, 目前是根据情况来的\n",
    "        if model_path!=None:\n",
    "            self.load_model(model_path)\n",
    "        else:\n",
    "            # model parameters\n",
    "            assert type(vocab_list)==list\n",
    "            self.vocab_list     = vocab_list\n",
    "            self.vocab_size     = vocab_list.__len__()\n",
    "            self.embedding_size = embedding_size\n",
    "            self.win_len        = win_len\n",
    "            self.num_sampled    = num_sampled\n",
    "            self.learning_rate  = learning_rate\n",
    "            self.logdir         = logdir\n",
    "\n",
    "            self.word2id = {}   # word => id 的映射\n",
    "            for i in range(self.vocab_size):\n",
    "                self.word2id[self.vocab_list[i]] = i\n",
    "\n",
    "            # train times\n",
    "            self.train_words_num = 0 # 训练的单词对数\n",
    "            self.train_sents_num = 0 # 训练的句子数\n",
    "            self.train_times_num = 0 # 训练的次数（一次可以有多个句子）\n",
    "\n",
    "            # train loss records\n",
    "            self.train_loss_records = collections.deque(maxlen=10) # 保存最近10次的误差\n",
    "            self.train_loss_k10 = 0\n",
    "\n",
    "        self.build_graph()\n",
    "        self.init_op()\n",
    "        if model_path!=None:\n",
    "            tf_model_path = os.path.join(model_path,'tf_vars')\n",
    "            self.saver.restore(self.sess,tf_model_path)\n",
    "\n",
    "    def init_op(self):\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "        self.sess.run(self.init)\n",
    "        self.summary_writer = tf.summary.FileWriter(self.logdir, self.sess.graph)\n",
    "\n",
    "    def build_graph(self):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self.train_inputs = tf.placeholder(tf.int32, shape=[self.batch_size])\n",
    "            self.train_labels = tf.placeholder(tf.int32, shape=[self.batch_size, 1])\n",
    "            self.embedding_dict = tf.Variable(\n",
    "                tf.random_uniform([self.vocab_size,self.embedding_size],-1.0,1.0)\n",
    "            )\n",
    "            self.nce_weight = tf.Variable(tf.truncated_normal([self.vocab_size, self.embedding_size],\n",
    "                                                              stddev=1.0/math.sqrt(self.embedding_size)))\n",
    "            self.nce_biases = tf.Variable(tf.zeros([self.vocab_size]))\n",
    "\n",
    "            # 将输入序列向量化\n",
    "            embed = tf.nn.embedding_lookup(self.embedding_dict, self.train_inputs) # batch_size\n",
    "\n",
    "            # 得到NCE损失\n",
    "            self.loss = tf.reduce_mean(\n",
    "                tf.nn.nce_loss(\n",
    "                    weights = self.nce_weight,\n",
    "                    biases = self.nce_biases,\n",
    "                    labels = self.train_labels,\n",
    "                    inputs = embed,\n",
    "                    num_sampled = self.num_sampled,\n",
    "                    num_classes = self.vocab_size\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # tensorboard 相关\n",
    "            tf.summary.scalar('loss',self.loss)  # 让tensorflow记录参数\n",
    "\n",
    "            # 根据 nce loss 来更新梯度和embedding\n",
    "            self.train_op = tf.train.GradientDescentOptimizer(learning_rate=learn_rate).minimize(self.loss)  # 训练操作\n",
    "\n",
    "            # 计算与指定若干单词的相似度\n",
    "            self.test_word_id = tf.placeholder(tf.int32,shape=[None])\n",
    "            vec_l2_model = tf.sqrt(  # 求各词向量的L2模\n",
    "                tf.reduce_sum(tf.square(self.embedding_dict),1,keep_dims=True)\n",
    "            )\n",
    "\n",
    "            avg_l2_model = tf.reduce_mean(vec_l2_model)\n",
    "            tf.summary.scalar('avg_vec_model',avg_l2_model)\n",
    "\n",
    "            self.normed_embedding = self.embedding_dict / vec_l2_model\n",
    "            # self.embedding_dict = norm_vec # 对embedding向量正则化\n",
    "            test_embed = tf.nn.embedding_lookup(self.normed_embedding, self.test_word_id)\n",
    "            self.similarity = tf.matmul(test_embed, self.normed_embedding, transpose_b=True)\n",
    "\n",
    "            # 变量初始化\n",
    "            self.init = tf.global_variables_initializer()\n",
    "\n",
    "            self.merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "            self.saver = tf.train.Saver()\n",
    "\n",
    "    def train_by_sentence(self, input_sentence=[]):\n",
    "        #  input_sentence: [sub_sent1, sub_sent2, ...]\n",
    "        # 每个sub_sent是一个单词序列，例如['这次','大选','让']\n",
    "        sent_num = input_sentence.__len__()\n",
    "        batch_inputs = []\n",
    "        batch_labels = []\n",
    "        for sent in input_sentence:\n",
    "            for i in range(sent.__len__()):\n",
    "                start = max(0,i-self.win_len)\n",
    "                end = min(sent.__len__(),i+self.win_len+1)\n",
    "                for index in range(start,end):\n",
    "                    if index == i:\n",
    "                        continue\n",
    "                    else:\n",
    "                        input_id = self.word2id.get(sent[i])\n",
    "                        label_id = self.word2id.get(sent[index])\n",
    "                        if not (input_id and label_id):\n",
    "                            continue\n",
    "                        batch_inputs.append(input_id)\n",
    "                        batch_labels.append(label_id)\n",
    "        if len(batch_inputs)==0:\n",
    "            return\n",
    "        batch_inputs = np.array(batch_inputs,dtype=np.int32)\n",
    "        batch_labels = np.array(batch_labels,dtype=np.int32)\n",
    "        batch_labels = np.reshape(batch_labels,[batch_labels.__len__(),1])\n",
    "\n",
    "        feed_dict = {\n",
    "            self.train_inputs: batch_inputs,\n",
    "            self.train_labels: batch_labels\n",
    "        }\n",
    "        _, loss_val, summary_str = self.sess.run([self.train_op,self.loss,self.merged_summary_op], feed_dict=feed_dict)\n",
    "\n",
    "        # train loss\n",
    "        self.train_loss_records.append(loss_val)\n",
    "        # self.train_loss_k10 = sum(self.train_loss_records)/self.train_loss_records.__len__()\n",
    "        self.train_loss_k10 = np.mean(self.train_loss_records)\n",
    "        if self.train_sents_num % 1000 == 0 :\n",
    "            self.summary_writer.add_summary(summary_str,self.train_sents_num)\n",
    "            print(\"{a} sentences dealed, loss: {b}\"\n",
    "                  .format(a=self.train_sents_num,b=self.train_loss_k10))\n",
    "\n",
    "        # train times\n",
    "        self.train_words_num += batch_inputs.__len__()\n",
    "        self.train_sents_num += input_sentence.__len__()\n",
    "        self.train_times_num += 1\n",
    "\n",
    "    def cal_similarity(self,test_word_id_list,top_k=10):\n",
    "        sim_matrix = self.sess.run(self.similarity, feed_dict={self.test_word_id:test_word_id_list})\n",
    "        sim_mean = np.mean(sim_matrix)\n",
    "        sim_var = np.mean(np.square(sim_matrix-sim_mean))\n",
    "        test_words = []\n",
    "        near_words = []\n",
    "        for i in range(test_word_id_list.__len__()):\n",
    "            test_words.append(self.vocab_list[test_word_id_list[i]])\n",
    "            nearst_id = (-sim_matrix[i,:]).argsort()[1:top_k+1]\n",
    "            nearst_word = [self.vocab_list[x] for x in nearst_id]\n",
    "            near_words.append(nearst_word)\n",
    "        print near_words\n",
    "        return test_words,near_words,sim_mean,sim_var\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        #2017/12/24\n",
    "        import pandas as pd\n",
    "        print len(self.vocab_list)\n",
    "        print len(self.sess.run(self.embedding_dict))\n",
    "        print type(self.vocab_list)\n",
    "        print len(list(self.sess.run(self.embedding_dict)))\n",
    "        my_save = pd.DataFrame({'chars':self.vocab_list,'embedding':list(self.sess.run(self.embedding_dict))})\n",
    "        my_save.to_csv('temp/char_embedding.csv',index=False,sep=',',encoding='utf-8')\n",
    "        \n",
    "        \n",
    "        \n",
    "        if os.path.isfile(save_path):\n",
    "            raise RuntimeError('the save path should be a dir')\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "\n",
    "        # 记录模型各参数\n",
    "        model = {}\n",
    "        var_names = ['vocab_size',      # int       model parameters\n",
    "                     'vocab_list',      # list\n",
    "                     'learning_rate',   # int\n",
    "                     'word2id',         # dict\n",
    "                     'embedding_size',  # int\n",
    "                     'logdir',          # str\n",
    "                     'win_len',         # int\n",
    "                     'num_sampled',     # int\n",
    "                     'train_words_num', # int       train info\n",
    "                     'train_sents_num', # int\n",
    "                     'train_times_num', # int\n",
    "                     'train_loss_records',  # int   train loss\n",
    "                     'train_loss_k10',  # int\n",
    "                     ]\n",
    "        for var in var_names:\n",
    "            model[var] = eval('self.'+var)\n",
    "\n",
    "        param_path = os.path.join(save_path,'params.pkl')\n",
    "        if os.path.exists(param_path):\n",
    "            os.remove(param_path)\n",
    "        with open(param_path,'wb') as f:\n",
    "            pkl.dump(model,f)\n",
    "\n",
    "        # 记录tf模型\n",
    "        tf_path = os.path.join(save_path,'tf_vars')\n",
    "        if os.path.exists(tf_path):\n",
    "            os.remove(tf_path)\n",
    "        self.saver.save(self.sess,tf_path)\n",
    "        \n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        if not os.path.exists(model_path):\n",
    "            raise RuntimeError('file not exists')\n",
    "        param_path = os.path.join(model_path,'params.pkl')\n",
    "        with open(param_path,'rb') as f:\n",
    "            model = pkl.load(f)\n",
    "            self.vocab_list = model['vocab_list']\n",
    "            self.vocab_size = model['vocab_size']\n",
    "            self.logdir = model['logdir']\n",
    "            self.word2id = model['word2id']\n",
    "            self.embedding_size = model['embedding_size']\n",
    "            self.learning_rate = model['learning_rate']\n",
    "            self.win_len = model['win_len']\n",
    "            self.num_sampled = model['num_sampled']\n",
    "            self.train_words_num = model['train_words_num']\n",
    "            self.train_sents_num = model['train_sents_num']\n",
    "            self.train_times_num = model['train_times_num']\n",
    "            self.train_loss_records = model['train_loss_records']\n",
    "            self.train_loss_k10 = model['train_loss_k10']\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #step1读取所有中文字符\n",
    "    allchar_txt = open(\"chars_all.txt\")\n",
    "    line = allchar_txt.readline().decode('utf-8')\n",
    "    allchar_txt.close()\n",
    "    chars_all = set(line)-set(u',\\{\\} ')\n",
    "    chars_all =chars_all | set(u'，。？！')\n",
    "    char_list = [x for x in chars_all]\n",
    "    print('文本中总共有{n1}个中文字符,全部字符进入字典'.format(n1=len(char_list)))\n",
    "          \n",
    "    # step2 读取文本，预处理\n",
    "    sentence_list = []\n",
    "    data = pd.read_csv(\"new_chinese_train.csv\", encoding='utf-8',header=0)\n",
    "    for label, content in zip(data.classes, data.content):\n",
    "        sentence_list.append(list(content))\n",
    "    print('一共有{n}个句子'.format(n=len(sentence_list)))\n",
    "\n",
    "\n",
    "\n",
    "    # 创建模型，训练\n",
    "    w2v = word2vec(vocab_list=char_list,    # 字典集\n",
    "                   embedding_size=16,\n",
    "                   win_len=4,\n",
    "                   learning_rate=1,\n",
    "                   num_sampled=100,         # 负采样个数\n",
    "                   logdir='/tmp/280')       # tensorboard记录地址\n",
    "\n",
    "        \n",
    "\n",
    "    test_word = [u'头',u'手',u'机',u'长',u'尊',u'皱',u'吃',u'喝',u'中',u'英',u'胜',u'东',u'男',u'蓝',u'南',u'地',u'的',u'育',u'酒',u'救']\n",
    "    test_id = [char_list.index(x) for x in test_word]\n",
    "    num_steps = 1000000\n",
    "    for i in range(num_steps):\n",
    "        sent = sentence_list[i%len(sentence_list)]\n",
    "        w2v.train_by_sentence([sent])\n",
    "    near_list = w2v.cal_similarity(test_id)[1]\n",
    "    i=0\n",
    "    for simlist in near_list:\n",
    "        print test_word[i].encode('utf-8')\n",
    "        print (simlist[0].encode('utf-8')+' '+simlist[1].encode('utf-8'),simlist[2].encode('utf-8'),simlist[3].encode('utf-8'),simlist[4].encode('utf-8'),simlist[5].encode('utf-8'),simlist[6].encode('utf-8'),simlist[6].encode('utf-8'))\n",
    "        i += 1\n",
    "    w2v.save_model('temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
